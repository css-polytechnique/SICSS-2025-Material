{"cells":[{"cell_type":"markdown","id":"bacb8a03","metadata":{"id":"bacb8a03"},"source":["# ü§ó Tutorial: Discovering Pretrained Models on Hugging Face\n","\n","> *A concise guide to navigating and selecting models from the Hugging Face Model Hub*  \n","Instructor: Yasmine Houri (yasmine.houri@ensae.fr)\n"]},{"cell_type":"markdown","id":"d625e809","metadata":{"id":"d625e809"},"source":["## What is Hugging Face?"]},{"cell_type":"markdown","id":"d32cfa36","metadata":{"id":"d32cfa36"},"source":["Hugging Face, Inc. is a French-American company based in New York City that develops computation tools for building applications using machine learning. It is most notable for its transformers library built for natural language processing applications and its platform that allows users to share machine learning models and datasets and showcase their work.\n","\n","History\n","The company was founded in 2016 by French entrepreneurs Cl√©ment Delangue, Julien Chaumond, and Thomas Wolf in New York City, originally as a company that developed a chatbot app targeted at teenagers.[1] The company was named after the U+1F917 ü§ó HUGGING FACE emoji. After open sourcing the model behind the chatbot, the company pivoted to focus on being a platform for machine learning.\n","\n","(Source: [Wikipedia](https://en.wikipedia.org/wiki/Hugging_Face))"]},{"cell_type":"markdown","id":"da51fc37","metadata":{"id":"da51fc37"},"source":["Hugging Face is the reference hub of open-source datasets, tools and pre-trained models. It is host to over 900,000 models, 200,000 datasets, and 300,000 demo applications, all designed to support collaborative and accessible machine learning. Let's learn how to interact with it! Although it is strongly focused on NLP, it also covers audio, video and multimodal tasks."]},{"cell_type":"markdown","id":"39dec988","metadata":{"id":"39dec988"},"source":["## Exploring Models on the Hugging Face Hub"]},{"cell_type":"markdown","id":"4c96c183","metadata":{"id":"4c96c183"},"source":["Let's visit the online [Hugging Face Hub](https://huggingface.co/models) together!"]},{"cell_type":"markdown","id":"c0add64d","metadata":{"id":"c0add64d"},"source":["## Trying Models in Python using ```pipeline```\n","\n","Access to Hugging Face through Python is via the ```transformers``` library.\n","\n","> **Transformers** is a library of pretrained natural language processing, computer vision, audio, and multimodal models for inference and training.  \n","> Transformers provides everything you need for inference or training with state-of-the-art pretrained models.  \n","> Use Transformers to train models on your data, build inference applications, and generate text with large language models.  \n",">  \n","> ‚Äî _Source: [Hugging Face Transformers Documentation](https://huggingface.co/docs/transformers/index)_\n"]},{"cell_type":"markdown","id":"673c3472","metadata":{"id":"673c3472"},"source":["### Pipeline"]},{"cell_type":"markdown","id":"143d4f08","metadata":{"id":"143d4f08"},"source":["**Pipeline** is a ready-to-use, integrated API for performing a wide range of machine learning tasks using any model from the Hugging Face Hub.  \n","Transformers has two pipeline classes:\n","- a generic [class](https://huggingface.co/docs/transformers/v4.52.1/en/main_classes/pipelines#transformers.Pipeline)\n","- individual task-specific classes (e.g. [TextGenerationPipeline](https://huggingface.co/docs/transformers/v4.52.1/en/main_classes/pipelines#transformers.TextGenerationPipeline))"]},{"cell_type":"code","execution_count":null,"id":"70d43432","metadata":{"id":"70d43432"},"outputs":[],"source":["# Install packages (uncomment if necessary)\n","# !pip install transformers"]},{"cell_type":"code","execution_count":null,"id":"2eb62971","metadata":{"id":"2eb62971","outputId":"135231c9-fddc-46bb-9c58-b4f750f974fd"},"outputs":[{"name":"stderr","output_type":"stream","text":["Device set to use cpu\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"data":{"text/plain":["[{'generated_text': 'The secret to baking a really good cake is the ability to change an egg, and when you bake it, it will just take a while for it to reach equilibrium. I would really love to see more ways to change things, but now I have'}]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import pipeline\n","\n","generator = pipeline(task=\"text-generation\", model=\"distilgpt2\")\n","# generator = pipeline(task=\"text-generation\",  max_new_tokens=20, model=\"tiiuae/falcon-rw-1b\")\n","generator(\"The secret to baking a really good cake is\")"]},{"cell_type":"markdown","id":"f690070c","metadata":{"id":"f690070c"},"source":["You can even prompt the generator with multiple sentences by passing them as a list:"]},{"cell_type":"code","execution_count":null,"id":"ac5f06cf","metadata":{"id":"ac5f06cf","outputId":"92e8bdcf-c249-4b23-b0e2-d4773b690517"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"data":{"text/plain":["[[{'generated_text': 'The secret to baking a really good cake is iced in vanilla yogurt, iced from almond milk, iced from chocolate milk and a small pinch of lemon juice.\\nThis cake is made with iced apple cider vinegar and with the help of'}],\n"," [{'generated_text': \"A baguette is iced cream that will give you a warm and comforting impression of the flavor buds.\\n\\n\\nWhat's this?\\nI'm a little confused, but a cream of chocolate with a really good flavor will quickly enhance the\"}]]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["generator([\"The secret to baking a really good cake is \", \"A baguette is \"])"]},{"cell_type":"markdown","id":"3c37ca1b","metadata":{"id":"3c37ca1b"},"source":["**Pipeline** can be used for various tasks. Let's try text summarization."]},{"cell_type":"code","execution_count":null,"id":"100b4adc","metadata":{"id":"100b4adc","outputId":"4bde7010-e1fd-4ffb-a1e5-970b7dec02e4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Device set to use cpu\n"]},{"name":"stdout","output_type":"stream","text":["The Summer Institute in Computational Social Science will take place from June 23 to July 3, 2025. It is open to social scientists, computer scientists, and a few seats could be reserved for people working professionally at this intersection. This year‚Äôs institute will focus on Large Language Models and Generative Artificial Intelligence. Participants are expected to fully attend and participate in the entire 9-day program.\n"]}],"source":["# Text summarization\n","\n","generator = pipeline(task=\"summarization\", model=\"facebook/bart-large-cnn\")\n","\n","text = \"\"\"\n","From June 23rd to July 3rd, 2025 the Institut Polytechnique de Paris will host the Summer Institute in Computational Social Science. It will take place at ENSAE, 5 Avenue Henri le Chatelier, Palaiseau, France (accepted applicants will receive an email with detailed pratical information about accomodation and how to reach the venue). This has been made possible by the generous support of SICSS, the Templeton Fondation, CREST, and Hi!Paris. The purpose of the Summer Institute is to bring together scholars interested in computational social science. The Summer Institute is for both social scientists (broadly conceived) and data scientists (broadly conceived).\n","\n","The Summer Institute is open to social scientists, computer scientists, and a few seats could be reserved for people working professionally at this intersection (such as data journalists) if applicable. Please note that although the first 5 days of SICSS-Paris 2025 will be held onsite, the 4 remaining days will be held remotely. This is to facilitate group work, and to foster inclusivity. The institute will involve lectures in the morning, lab sessions in the afternoon, and about 6 evening guest lectures. During the second week, the participants will take part in group work aimed at advancing a research project and attend remote guest lectures as well.\n","\n","This year‚Äôs institute will focus on Large Language Models and Generative Artificial Intelligence. Sessions will take students all the way from an introduction to text analysis through to practical uses of and critical perspectives on deep learning for text analysis in the social sciences. Participants will have ample opportunities to discuss their ideas and research with the organizers, with other participants, as well as with guest speakers. Because we are committed to open and reproducible research, all materials created for the Summer Institute will be released open-source (find materials from the 2023 edition here).\n","\n","Participation is restricted to advanced Ph.D. students, postdoctoral researchers, and junior faculty (within 7 years of their Ph.D). We welcome applicants from all backgrounds and fields of study, especially junior faculty from neighboring institutions near Palaiseau, France. About 25-30 participants will be invited. Participants are expected to fully attend and participate in the entire 9-day program, which includes 5 days onsite and 4 remote, but we are open to alternative arrangements for faculty members.\n","\"\"\"\n","\n","summary = generator(text, max_length=150, min_length=40, do_sample=False)\n","print(summary[0]['summary_text'])\n"]},{"cell_type":"markdown","id":"76b61f0b","metadata":{"id":"76b61f0b"},"source":["The ```pipeline``` function has a range of parameters. The user is required to specify at least a ```task identifier```, ```model```, and the appropriate ```input```. To see other parameters, visit this [page](https://huggingface.co/docs/transformers/v4.52.2/en/main_classes/pipelines#transformers.pipeline)."]},{"cell_type":"markdown","id":"e45bddc5","metadata":{"id":"e45bddc5"},"source":["## How to choose a good model?"]},{"cell_type":"markdown","id":"4c3b8e18","metadata":{"id":"4c3b8e18"},"source":["> Already know which model to use? Great ‚Äî go ahead and load it!  \n","> Not sure which model to choose?  üëâ Explore the [Hugging Face Hub](https://huggingface.co/) to find the right model for your task.\n","\n","Consider:\n","\n","- ‚úÖ Task suitability\n","\n","- üß™ Performance (look at evaluation metrics)\n","\n","- üìú License (especially for commercial use)\n","\n","- üß† Model size vs. speed tradeoffs\n"]},{"cell_type":"markdown","id":"7ea24fd6","metadata":{"id":"7ea24fd6"},"source":["## üöÄ Your Turn!\n","\n","Choose any model from the ü§ó Hugging Face Hub and use the `pipeline` interface to run a task of your choice.\n","\n","### üß† Suggested Tasks:\n","- Sentiment analysis\n","- Text generation\n","- Named entity recognition\n","- Text summarization\n","- Translation\n","\n","---\n","\n","### ‚úÖ Instructions:\n","1. Visit [huggingface.co/models](https://huggingface.co/models) and pick a model.\n","2. Use the `pipeline` from `transformers` to load and apply the model.\n","3. Try it out on your own input data and display the results!\n","\n","> üìù *Example*: Use a sentiment analysis model to analyze the tone of a paragraph.\n"]},{"cell_type":"markdown","id":"eed0efb7","metadata":{"id":"eed0efb7"},"source":["# üéâ You‚Äôre now all set to work with Hugging Face models throughout the Summer School. Happy coding!"]}],"metadata":{"kernelspec":{"display_name":"nlp","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}